---
title: "DATA 607 - Project 3"
author: "Team Silver Fox"
date: "`r Sys.Date()`"
output: html_document
---


```{r load-packages, include=FALSE}
library(tidyverse)
library(openintro)
library(dplyr)
library(tidyr)
library(RCurl)
library(ggplot2)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### BACKGROUND

> What are the most valued data science skills?

Answering this question formed the crux of our project. 

We collaborated in understanding the question at hand, brainstorming an approach and where we might pull data from, deciding on a dataset and then acquiring, tidying & transforming, visualizing & analyzing this dataset before ultimately coming to the conclusion we'll present later.

Along the way, *Team Silver Fox*  collaborated virtually on Slack, Google Docs, Google Meet, and Github and [insert what we did – in short] in answering the question posed above.

Without further adieu, let’s introduce *Team Silver Fox*:

* **Dan Rosenfeld** – one sentence bio. [Github link]
* **Magnus Skonberg** – one sentence bio. [Github link]
* **Mustafa Telab** – one sentence bio. [Github link]
* **Josef Waples** – one sentence bio. [Github link].

### APPROACH EXPLANATION

We started our search by utilizing Kaggle’s self proclaimed “most comprehensive dataset available on the state of ML and data science”, pulling what we deemed useful from this set.

From our findings of the general dataset, we then applied a “value filter” (ie. only considering responses above a certain income, education, or experience level) to see how the general perspective of essential skills differed from that of a more seasoned (or market-valued) perspective.

At this point, we then transitioned to comparing data science skills deemed as valuable in Kaggle's 2018 survey with the most in-demand skills for data scientists across multiple job sites. This "pro level" dataset, prepared by Jeff Hale, was pulled in to paint the picture of contrast (if there was any) between the skills data scientists deem as most valuable (ie. those doing the work) vs. those that employers hire for (ie. hiring managers).

By contrasting our sets via different techniques and visualizations, we further refined our own findings and actually added a layer.

Our general approach is outlined below:

1. Pre-screen: after viewing the initial Kaggle (multipleChoiceResponses.csv) dataset and seeing that we would not be able to access this dataset via Github due to its size (39+ MB), we deemed “pre-screening” the dataset an essential step. We reviewed all 50 questions from the SurveySchema.csv file and marked those that we deemed applicable to providing insight for what the most valuable data science skills are. We then removed all inapplicable columns from the multipleChoiceResponses.csv. Once this dataset had been “pre-screened” it was uploaded to Github along with Jeff Hale’s general and software skill csv files (for later comparison).

<!--If this step is unclear please let me (Magnus) know. I can flesh out more exactly what the criteria was for keeping v. deleting columns (questions) ...-->

2. Acquire data: get the URL, read the .csv from Github (in its raw form), and put it in tabular form.
3. Tidy and transform: our Kaggle dataset and put Jeff Hale’s in a form we can compare / pull from.
4. Filter our dataset for another interpretation of “valuable” (education, income, experience level).
5. Interpret our filtered v our filtered datasets and see what we can pull.
6. Introduce Jeff Hale’s pretty data for comparison and see what we can lean on. Introduce general skills (something missing from our interpretation upto this point).
7. Visualize and analyze.
8. Conclude.

<!--This is a work-in-progress. There are probably a number of points above that could be better worded / fleshed out etc. I was just chug-a-lugging along today and wanted to jot out where our analysis could go based on the words "most valuable" ...-->

### ACQUIRE DATA

First we read our multiple choice dataset from the 2018 Kaggle survey.
```{r}
#Get URL, read .csv (in raw form) from github, and put into tabular form
url <- getURL("https://raw.githubusercontent.com/Magnus-PS/CUNY-SPS-DATA-607/Project-3/pertinent_mc_resps.csv")
data1 <- read.csv(text = url)
mc_resps <- as_tibble(data1)

#Show what we're working with:
mc_resps

#Display dimensions: 23860 rows x 43 columns
dim(mc_resps)

```

Next we download our technical skills dataset (for later comparison).

```{r}
#Get URL, read .csv (in raw form) from github, and put into tabular form
url2 <- getURL("https://raw.githubusercontent.com/Magnus-PS/CUNY-SPS-DATA-607/Project-3/ds_software.csv")
data2 <- read.csv(text = url2)
tech_skills <- as_tibble(data2)

#Show what we're working with:
tech_skills

#Our output is 44 rows x 12 columns
dim(tech_skills)

```

Finally, we download our general skills dataset (for later comparison).

```{r}
#Get URL, read .csv (in raw form) from github, and put into tabular form
url3 <- getURL("https://raw.githubusercontent.com/Magnus-PS/CUNY-SPS-DATA-607/Project-3/ds_general.csv")
data3 <- read.csv(text = url3)
genl_skills <- as_tibble(data3)

#Show what we're working with:
genl_skills

#Our output is 30 rows x 5 columns
dim(genl_skills)

```

### TIDY & TRANSFORM

Create table of questions with Q_ID and Question as columns:

```{r}
#Extract all unique questions into questions table
questions <- mc_resps[1,]
colnames(questions)

#Compress questions with multiple columns into one
comp_qs <- questions[ -c(6:12,14:31,33,35,38:43) ]

#Rename column titles for same format (ie. Q4)
names(comp_qs)[names(comp_qs) == "Q11_Part_1"] <- "Q11"
names(comp_qs)[names(comp_qs) == "Q16_Part_1"] <- "Q16"
names(comp_qs)[names(comp_qs) == "Q34_Part_1"] <- "Q34"

#Transpose for a long dataframe
qs_long <- gather(comp_qs, "Q #", "Question", 1:10, factor_key=TRUE)

#Replace the question number with a question ID (ie. Q4 --> 1)
qs_long$Q_ID <- seq.int(nrow(qs_long)) 
qs_long <- qs_long[ -c(1) ]
qs_final <- qs_long[c("Q_ID", "Question")]
qs_final

```

Create the table of Answers (with Q_ID, A_ID, Answer as columns) *and then* gather counts for unique variables related to the Software Skills, General Skills, and the Value Filter:

```{r}
#Further widdle our dataset down: remove all columns with "OTHER" labels and non-valuable entries, remove 1st row (question statement)
answers <- mc_resps[ -c(11:12,29:31,33,35,43) ]
answers <- answers[-1,]

```

Gather counts for unique variables related to SOFTWARE SKILLS: 

```{r}
#Software language "regular basis" (Q16) count
##Gather associated answers into one column, cut out irrelevant columns, then count
reg_basis <- gather(answers, key = "Q16_A_ID", value = "Q16_Answer", Q16_Part_1, Q16_Part_2, Q16_Part_3, Q16_Part_4, Q16_Part_5, Q16_Part_6, Q16_Part_7, Q16_Part_8, Q16_Part_9, Q16_Part_10, Q16_Part_11, Q16_Part_12, Q16_Part_13, Q16_Part_14, Q16_Part_15, Q16_Part_16)
reg_basis
reg_basis <- reg_basis[ -c(1:19) ]
reg_basis %>% count(Q16_Answer, sort = TRUE)

#Software language "use most often" (Q17) count
answers %>% count(Q17, sort = TRUE)

#Software language "recommend to aspiring DSs" (Q18) count
answers %>% count(Q18, sort = TRUE)

```

Gather counts for unique variables related to GENERAL SKILLS: We may end up using this data in a different way than originally intended but that's TBD ...

```{r}
#Machine learning (Q10) count
answers %>% count(Q10, sort = TRUE)

#Daily activities (Q11) count
##Gather associated answers into one column, cut out irrelevant columns, then count
all_daily <- gather(answers, key = "Q11_A_ID", value = "Q11_Answer", Q11_Part_1, Q11_Part_2, Q11_Part_3, Q11_Part_4, Q11_Part_5, Q11_Part_6)
all_daily <- all_daily[ -c(1:29) ]
all_daily %>% count(Q11_Answer, sort = TRUE)

#Software activity (Q23) count
answers %>% count(Q23, sort = TRUE)

#% use time (Q34) count
##Gather associated answers into one column, cut out irrelevant columns, then count
all_time <- gather(answers, key = "Q34_A_ID", value = "Q34_Answer", Q34_Part_1, Q34_Part_2, Q34_Part_3, Q34_Part_4, Q34_Part_5, Q34_Part_6)
all_time <- all_time[ -c(1:29) ]
all_time %>% count(Q34_Answer, sort = TRUE)
```

Gather counts for unique variables related to the VALUE FILTER: These can then be plotted, graphed, etc. or used to build a "filter" by considering only entries where, for instance, the respondent makes >=$100k ...

```{r}
##Education level count
answers %>% count(Q4, sort = TRUE)
##Experience count
answers %>% count(Q8, sort = TRUE)
##Income count
answers %>% count(Q9, sort = TRUE)

```

At this point we could visualize and analyze data for software v general skills. Then we could visualize and analyze data with a "value filter" applied and see if there's any contrast or insight gained by pulling from a subset of the original data (ie. high income DSs).

Tidy and transform: put Jeff Hale’s in a form we can compare / pull from. *And then* introduce Jeff Hale’s pretty data for comparison and see what we can lean on.

Gather counts for unique variables related to SOFTWARE SKILLS for Jeff Hale's dataset:
```{r}
#Explore results for each job board
##LinkedIn software skills count
LinkedIn_sw <- tech_skills[ c(1,2)]
LinkedIn_sw
##Indeed software skills count
Indeed_sw <- tech_skills[ c(1,3)]
Indeed_sw
##SimplyHired software skills count
SimplyHired_sw <- tech_skills[ c(1,4)]
SimplyHired_sw
##Monster software skills count
Monster_sw <- tech_skills[ c(1,5)]
Monster_sw

##It could be useful to scrap the code above and just plot for each software language in a horizontal bar plot with each job board in a different color

##Then sum all rows to get all job search results per keyword and re-plot

```

Gather counts for unique variables related to GENERAL SKILLS for Jeff Hale's dataset:
```{r}

#Explore results for each job board
##LinkedIn general skills count
LinkedIn_gen <- genl_skills[ c(1,2)]
LinkedIn_gen
##Indeed general skills count
Indeed_gen <- genl_skills[ c(1,3)]
Indeed_gen
##SimplyHired general skills count
SimplyHired_gen <- genl_skills[ c(1,4)]
SimplyHired_gen
##Monster general skills count
Monster_gen <- genl_skills[ c(1,5)]
Monster_gen

##It could be useful to scrap the code above and just plot for each general skill in a horizontal bar plot with each job board in a different color

##Then sum all rows to get all job search results per keyword and re-plot


```

### ANALYZE